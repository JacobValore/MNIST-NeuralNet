# MNIST-NeuralNet
A basic neural network, coded from scratch, in Java. Originally coded in 2018, the knowledge and inspiration to code this came from [3Blue1Brown's YouTube series on Neural Networks](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi). I was also inspired by my highschool AP Calculus teacher, Mr.Chao, who had recently taught me calculus. This neural network can easily reach about 96.5% accuracy.

The code starts in Main.java, where many of the network parameters can be set. The nodes are then created and initialized, and the MNIST data read in and placed into batches. After each batch, the error for each node is backpropagated through the network. Once all epochs are complete, the testing data is read in and tested against the neural net. The final statistics are printed to console and the program is finished.

The essential functions in Node.java are activate() and backpropagate(). The activate() function propagates each image forward through the network using a sigmoid function. The backpropagate() function uses calculus and error calculations to determine how the weights and biases should be adjusted for each node. The specifics for the calculus used can be found in the video series linked above.

FileIO.java was originally used to read in .PNG files to train the net, however reading in many images and obtaining each pixel's brightness is very slow. To solve this issue, I found an MNIST Reader on github to read from the original MNIST database file (essentially a series of pixel values in a row). This was much faster, actually allowing my laptop to run many epochs of training data through the neural net. Now there is only a single function used in FileIO.java, called convertToNode, which essentially just flattens a 2D integer array of pixel brightness values into a 1D Node array.
